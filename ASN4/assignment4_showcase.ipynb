{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 421: NLP - Assignment 4 üî•\n",
    "## Named Entity Recognition, TF-IDF, and PPMI - Let's Get It\n",
    "\n",
    "---\n",
    "\n",
    "**Author:** [Your Name]  \n",
    "**Date:** November 2025  \n",
    "**Course:** CS 421 - Natural Language Processing\n",
    "\n",
    "---\n",
    "\n",
    "### Assignment Overview - What We Cookin\n",
    "\n",
    "This assignment explores three NLP concepts that go crazy:\n",
    "\n",
    "1. **TF-IDF Vectorization** (25 points) - Building a document vectorizer from scratch (no cap)\n",
    "2. **PPMI Calculation** (5 points) - Computing word association vibes\n",
    "3. **Named Entity Recognition** (20 points) - Deep learning with LSTM networks (big brain time)\n",
    "\n",
    "**Total Points:** 50\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports - Loading Up The Arsenal\n",
    "\n",
    "First, let's import all the libraries we need - gotta get the whole squad ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries - the foundation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter, defaultdict\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # no need for warnings killin our vibe\n",
    "\n",
    "# NLP libraries - the language processors\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Deep learning libraries - the big guns\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "\n",
    "# Word embeddings - the semantic sauce\n",
    "import gensim.downloader as api\n",
    "\n",
    "# Set style for better visualizations (aesthetic gang)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"All libraries imported successfully! We ready to roll üöÄ\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Keras version: {keras.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Question 1: TF-IDF Vectorization and Cosine Similarity\n",
    "\n",
    "### üìö Theory - The Math Behind The Magic\n",
    "\n",
    "**TF-IDF (Term Frequency-Inverse Document Frequency)** is a numerical stat that shows how important a word is to a doc - basically tells us which words are fire and which are mid.\n",
    "\n",
    "**Formulas (the spicy math):**\n",
    "- **Term Frequency (TF):** `tf(t,d) = log‚ÇÅ‚ÇÄ(count(t,d) + 1)` - how often word shows up\n",
    "- **Inverse Document Frequency (IDF):** `idf(t) = log‚ÇÅ‚ÇÄ(N / df_t)` - how rare the word is across docs\n",
    "- **TF-IDF:** `tfidf(t,d) = tf(t,d) √ó idf(t)` - the final boss combo\n",
    "\n",
    "Where:\n",
    "- `t` = term (the word we checkin)\n",
    "- `d` = document (the text we searchin)\n",
    "- `N` = total number of documents (the whole collection)\n",
    "- `df_t` = number of documents containing term t (popularity meter)\n",
    "\n",
    "**Cosine Similarity** measures how similar two vectors are - basically checking if they got the same vibe:\n",
    "```\n",
    "cosine_similarity(A, B) = (A ¬∑ B) / (||A|| √ó ||B||)\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation - Building This Bad Boy From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfIdfVectorBoss:\n",
    "    \"\"\"\n",
    "    Custom TF-IDF Vectorizer - we buildin this from scratch no cap\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.wordDict = {}  # maps words to their index positions (the roster)\n",
    "        self.idfVibes = {}  # stores idf scores for each word (rarity meter)\n",
    "        self.totalDocs = 0  # how many docs we workin with\n",
    "\n",
    "    def buildVocabSwag(self, docsList):\n",
    "        \"\"\"Build up our vocabulary from all the docs - gotta know what words we got\"\"\"\n",
    "        uniqueWords = set()\n",
    "        for singleDoc in docsList:\n",
    "            uniqueWords.update(singleDoc)\n",
    "        \n",
    "        # Make a dictionary mapping words to numbers (indexin the homies)\n",
    "        self.wordDict = {word: idx for idx, word in enumerate(sorted(uniqueWords))}\n",
    "        print(f\"‚úì Vocabulary got {len(self.wordDict)} words in it, that's bussin\")\n",
    "\n",
    "    def calculateDocFreq(self, docsList):\n",
    "        \"\"\"Count how many docs each word appears in - popularity contest fr\"\"\"\n",
    "        freqTracker = defaultdict(int)\n",
    "        for singleDoc in docsList:\n",
    "            uniqueWordsInDoc = set(singleDoc)\n",
    "            for word in uniqueWordsInDoc:\n",
    "                freqTracker[word] += 1\n",
    "        return dict(freqTracker)\n",
    "\n",
    "    def getTermFrequency(self, wordToCheck, docToSearch):\n",
    "        \"\"\"Calculate term frequency - basically how much this word shows up\"\"\"\n",
    "        wordCount = docToSearch.count(wordToCheck)\n",
    "        return math.log10(wordCount + 1)\n",
    "\n",
    "    def getIdfScore(self, wordToLookup):\n",
    "        \"\"\"Get the inverse document frequency - tells us how rare/common a word is\"\"\"\n",
    "        if wordToLookup in self.idfVibes:\n",
    "            return self.idfVibes[wordToLookup]\n",
    "        return 0.0\n",
    "\n",
    "    def fitTheData(self, docsList):\n",
    "        \"\"\"Train this bad boy on our docs - learn all the word stats\"\"\"\n",
    "        self.totalDocs = len(docsList)\n",
    "        self.buildVocabSwag(docsList)\n",
    "        \n",
    "        freqDict = self.calculateDocFreq(docsList)\n",
    "        \n",
    "        # Calculate IDF for each word (find out who's rare)\n",
    "        for word in self.wordDict:\n",
    "            docFreq = freqDict.get(word, 0)\n",
    "            if docFreq > 0:\n",
    "                self.idfVibes[word] = math.log10(self.totalDocs / docFreq)\n",
    "            else:\n",
    "                self.idfVibes[word] = 0.0\n",
    "        \n",
    "        print(f\"‚úì Fitted on {self.totalDocs} documents - we ready to roll!\")\n",
    "\n",
    "    def makeTfidfVector(self, singleDoc):\n",
    "        \"\"\"Turn a document into a TF-IDF vector - convert words to numbers\"\"\"\n",
    "        vectorSwag = np.zeros(len(self.wordDict))\n",
    "        \n",
    "        for word in singleDoc:\n",
    "            if word in self.wordDict:\n",
    "                wordPosition = self.wordDict[word]\n",
    "                termFreq = self.getTermFrequency(word, singleDoc)\n",
    "                idfValue = self.getIdfScore(word)\n",
    "                vectorSwag[wordPosition] = termFreq * idfValue\n",
    "        \n",
    "        return vectorSwag\n",
    "\n",
    "    def transformDocs(self, docsList):\n",
    "        \"\"\"Transform a whole bunch of docs into TF-IDF matrix\"\"\"\n",
    "        bigMatrix = np.zeros((len(docsList), len(self.wordDict)))\n",
    "        \n",
    "        for docIdx, singleDoc in enumerate(docsList):\n",
    "            bigMatrix[docIdx] = self.makeTfidfVector(singleDoc)\n",
    "        \n",
    "        return bigMatrix\n",
    "\n",
    "    def fitAndTransform(self, docsList):\n",
    "        \"\"\"Do the fit and transform in one shot - efficiency gang\"\"\"\n",
    "        self.fitTheData(docsList)\n",
    "        return self.transformDocs(docsList)\n",
    "\n",
    "\n",
    "def calculateCosineSimilarity(firstVec, secondVec):\n",
    "    \"\"\"Calculate cosine similarity - see how similar two vectors are\"\"\"\n",
    "    dotProductVibes = np.dot(firstVec, secondVec)\n",
    "    magnitudeFirst = np.linalg.norm(firstVec)\n",
    "    magnitudeSecond = np.linalg.norm(secondVec)\n",
    "    \n",
    "    if magnitudeFirst == 0 or magnitudeSecond == 0:\n",
    "        return 0.0  # can't divide by zero, that ain't it chief\n",
    "    \n",
    "    return dotProductVibes / (magnitudeFirst * magnitudeSecond)\n",
    "\n",
    "print(\"TF-IDF Vectorizer class defined! Ready to cook üî•\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CoNLL2003 Dataset - Getting The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load that CoNLL2003 dataset (classic NLP dataset fr fr)\n",
    "print(\"Loadin CoNLL2003 dataset... hold up...\")\n",
    "datasetStash = load_dataset(\"conll2003\")\n",
    "\n",
    "# Extract tokens from training set\n",
    "trainingDataRaw = datasetStash['train']\n",
    "\n",
    "# Treat each row as a document (we treating each sentence as its own vibe)\n",
    "docsCollection = []\n",
    "for idx in range(min(1000, len(trainingDataRaw))):  # using first 1000 cuz we aint got all day\n",
    "    tokensFromDoc = trainingDataRaw[idx]['tokens']\n",
    "    docsCollection.append([token.lower() for token in tokensFromDoc])\n",
    "\n",
    "print(f\"‚úì Loaded {len(docsCollection)} documents from CoNLL2003, we eatin good!\")\n",
    "print(f\"\\nSample document: {' '.join(docsCollection[0][:20])}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build TF-IDF Matrix - Making The Magic Happen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train our TF-IDF boss\n",
    "vectorizerGoat = TfIdfVectorBoss()\n",
    "tfidfMatrixBig = vectorizerGoat.fitAndTransform(docsCollection)\n",
    "\n",
    "print(f\"\\n‚úì TF-IDF Matrix shape: {tfidfMatrixBig.shape}\")\n",
    "print(f\"  ‚Üí {tfidfMatrixBig.shape[0]} documents √ó {tfidfMatrixBig.shape[1]} features\")\n",
    "print(f\"  That's {tfidfMatrixBig.shape[0] * tfidfMatrixBig.shape[1]:,} total values - we packin heat!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize TF-IDF Matrix - See The Pattern\n",
    "\n",
    "Let's visualize a heatmap of the TF-IDF values - basically see which words hit different in each doc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize TF-IDF matrix (first 20 documents, top 30 words)\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "# Get top words by average TF-IDF (find the MVPs)\n",
    "avgTfidfScores = tfidfMatrixBig.mean(axis=0)\n",
    "topWordIndices = np.argsort(avgTfidfScores)[-30:]\n",
    "\n",
    "# Get word labels (the roster names)\n",
    "idxToWordMap = {v: k for k, v in vectorizerGoat.wordDict.items()}\n",
    "topWordsList = [idxToWordMap[i] for i in topWordIndices]\n",
    "\n",
    "# Plot heatmap (make it look fire)\n",
    "subsetMatrix = tfidfMatrixBig[:20, topWordIndices]\n",
    "sns.heatmap(subsetMatrix, cmap='YlOrRd', cbar_kws={'label': 'TF-IDF Score'},\n",
    "            xticklabels=topWordsList, yticklabels=[f'Doc {i}' for i in range(20)],\n",
    "            ax=ax)\n",
    "ax.set_title('TF-IDF Heatmap: Top 30 Words Across First 20 Documents üî•', fontsize=16, pad=20)\n",
    "ax.set_xlabel('Words', fontsize=12)\n",
    "ax.set_ylabel('Documents', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Heatmap shows which words are most important (higher TF-IDF = more fire) in each document.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity Analysis - Comparing The Vibes\n",
    "\n",
    "Now let's compute cosine similarity for the required sentence pairs - see which sentences got similar energy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sentences to compare (the moment of truth)\n",
    "testSentencePairs = [\n",
    "    (\"I love football\", \"I do not love football\"),\n",
    "    (\"I follow cricket\", \"I follow baseball\")\n",
    "]\n",
    "\n",
    "resultsCollection = []\n",
    "\n",
    "print(\"Computing cosine similarities - let's see who's similar:\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for firstSentence, secondSentence in testSentencePairs:\n",
    "    # Tokenize (break sentences into words and make em lowercase)\n",
    "    tokensFirst = firstSentence.lower().split()\n",
    "    tokensSecond = secondSentence.lower().split()\n",
    "    \n",
    "    # Get TF-IDF vectors (convert to numbers)\n",
    "    vecFirst = vectorizerGoat.makeTfidfVector(tokensFirst)\n",
    "    vecSecond = vectorizerGoat.makeTfidfVector(tokensSecond)\n",
    "    \n",
    "    # Calculate how similar they are (the vibe check)\n",
    "    similarityScore = calculateCosineSimilarity(vecFirst, vecSecond)\n",
    "    \n",
    "    resultsCollection.append({\n",
    "        'Sentence 1': firstSentence,\n",
    "        'Sentence 2': secondSentence,\n",
    "        'Cosine Similarity': similarityScore,\n",
    "        'Vibe Check': 'Similar vibes ‚úì' if similarityScore > 0.5 else 'Different energy ‚úó'\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nüìù Pair {len(resultsCollection)}:\")\n",
    "    print(f\"   Sentence 1: '{firstSentence}'\")\n",
    "    print(f\"   Sentence 2: '{secondSentence}'\")\n",
    "    print(f\"   Cosine Similarity: {similarityScore:.4f}\")\n",
    "    print(f\"   Vibe Check: {resultsCollection[-1]['Vibe Check']}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# Create results DataFrame (organize it nice)\n",
    "resultsDataframe = pd.DataFrame(resultsCollection)\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(resultsDataframe.to_string(index=False))\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Cosine Similarity Results - See The Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize cosine similarities (make it aesthetic)\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "pairLabels = [f\"Pair {i+1}\" for i in range(len(resultsCollection))]\n",
    "similarityValues = [r['Cosine Similarity'] for r in resultsCollection]\n",
    "barColors = ['#2ecc71' if s > 0.5 else '#e74c3c' for s in similarityValues]  # green for similar, red for different\n",
    "\n",
    "barsPlotted = ax.bar(pairLabels, similarityValues, color=barColors, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "ax.axhline(y=0.5, color='black', linestyle='--', linewidth=1, label='Similarity Threshold (0.5)')\n",
    "ax.set_ylabel('Cosine Similarity', fontsize=12)\n",
    "ax.set_xlabel('Sentence Pairs', fontsize=12)\n",
    "ax.set_title('Cosine Similarity Between Sentence Pairs - Vibe Check üéØ', fontsize=16, pad=20)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars (show the exact scores)\n",
    "for barElement, simScore in zip(barsPlotted, similarityValues):\n",
    "    barHeight = barElement.get_height()\n",
    "    ax.text(barElement.get_x() + barElement.get_width()/2., barHeight,\n",
    "            f'{simScore:.4f}',\n",
    "            ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìä Q1 Analysis - What We Learned\n",
    "\n",
    "**Key Observations:**\n",
    "\n",
    "1. **Pair 1: \"I love football\" vs \"I do not love football\"**\n",
    "   - These sentences share mad words but got opposite meanings cuz of \"not\"\n",
    "   - The cosine similarity reflects the word overlap but misses the negation vibe\n",
    "   - TF-IDF be like \"yo they got similar words\" but ain't catchin the opposite energy\n",
    "   \n",
    "2. **Pair 2: \"I follow cricket\" vs \"I follow baseball\"**\n",
    "   - These sentences got similar structure and meaning fr\n",
    "   - Only one word differs (\"cricket\" vs \"baseball\") - both are sports tho\n",
    "   - High similarity indicates they vibin on the same wavelength\n",
    "\n",
    "**Conclusion:** TF-IDF with cosine similarity effectively captures lexical similarity (word overlap) but may not always capture semantic meaning (actual vibe). It's like checkin if two people wearin the same outfit vs if they got the same personality - sometimes they match, sometimes they don't.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: PPMI (Positive Pointwise Mutual Information)\n",
    "\n",
    "### üìö Theory - Finding Word Squads\n",
    "\n",
    "**Pointwise Mutual Information (PMI)** measures which words like to hang out together:\n",
    "\n",
    "```\n",
    "PMI(x, y) = log‚ÇÇ(p(x,y) / (p(x) √ó p(y)))\n",
    "```\n",
    "\n",
    "**Positive PMI (PPMI)** only keeps the positive vibes:\n",
    "```\n",
    "PPMI(x, y) = max(PMI(x, y), 0)\n",
    "```\n",
    "\n",
    "Where:\n",
    "- `p(x)` = how often word x shows up (popularity)\n",
    "- `p(y)` = how often word y shows up (popularity)\n",
    "- `p(x,y)` = how often x and y chill together (co-occurrence)\n",
    "\n",
    "**Interpretation:** Higher PPMI = words are homies (appear together more than random chance)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation - Building The Association Finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculatePpmiScores(wordsList):\n",
    "    \"\"\"\n",
    "    Calculate PPMI - basically finds which words like to hang out together\n",
    "    \"\"\"\n",
    "    # Count how many times each word appears (popularity contest)\n",
    "    wordCountTracker = Counter(wordsList)\n",
    "    totalWordCount = len(wordsList)\n",
    "    \n",
    "    # Count word pairs that appear next to each other (who hangs with who)\n",
    "    pairCountTracker = Counter()\n",
    "    for idx in range(len(wordsList) - 1):\n",
    "        wordPair = (wordsList[idx], wordsList[idx + 1])\n",
    "        pairCountTracker[wordPair] += 1\n",
    "    \n",
    "    totalPairsCount = sum(pairCountTracker.values())\n",
    "    \n",
    "    # Calculate PPMI for each pair (find the real homies)\n",
    "    ppmiResultDict = {}\n",
    "    \n",
    "    for (firstWord, secondWord), pairAppearances in pairCountTracker.items():\n",
    "        # Calculate probabilities (math time)\n",
    "        probFirst = wordCountTracker[firstWord] / totalWordCount\n",
    "        probSecond = wordCountTracker[secondWord] / totalWordCount\n",
    "        probPair = pairAppearances / totalPairsCount\n",
    "        \n",
    "        # Calculate PMI then PPMI\n",
    "        if probFirst > 0 and probSecond > 0 and probPair > 0:\n",
    "            pmiScore = math.log2(probPair / (probFirst * probSecond))\n",
    "            # PPMI = only keep positive scores (no negativity here)\n",
    "            ppmiScore = max(pmiScore, 0)\n",
    "            ppmiResultDict[(firstWord, secondWord)] = ppmiScore\n",
    "    \n",
    "    return ppmiResultDict\n",
    "\n",
    "print(\"PPMI function defined! Ready to find word squads üíØ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Simple Case - Testing The Waters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example from the assignment sheet\n",
    "exampleWordList = ['a', 'b', 'a', 'c']\n",
    "ppmiResults = calculatePpmiScores(exampleWordList)\n",
    "\n",
    "print(\"Example: words = ['a', 'b', 'a', 'c']\\n\")\n",
    "print(\"PPMI Results (who's vibin together):\")\n",
    "print(\"=\" * 40)\n",
    "for wordPair, ppmiVal in sorted(ppmiResults.items()):\n",
    "    print(f\"  {wordPair}: {ppmiVal:.4f}\")\n",
    "print(\"=\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Realistic Sentence - The Real Deal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a more realistic example (actual sentence vibes)\n",
    "sentenceExample = \"the cat sat on the mat the dog sat on the log\".split()\n",
    "ppmiResults2 = calculatePpmiScores(sentenceExample)\n",
    "\n",
    "print(f\"Example: '{' '.join(sentenceExample)}'\\n\")\n",
    "print(\"PPMI Results (top 10 word combos that go hard):\")\n",
    "print(\"=\" * 50)\n",
    "for wordPair, ppmiVal in sorted(ppmiResults2.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "    print(f\"  {wordPair[0]:8s} ‚Üí {wordPair[1]:8s} : {ppmiVal:.4f}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize PPMI Values - See The Associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization (make it look clean)\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "pairNames = [f\"{p[0]}-{p[1]}\" for p in ppmiResults2.keys()]\n",
    "ppmiValues = list(ppmiResults2.values())\n",
    "\n",
    "# Sort by value (highest associations first)\n",
    "sortedPairData = sorted(zip(pairNames, ppmiValues), key=lambda x: x[1], reverse=True)\n",
    "sortedPairNames = [p[0] for p in sortedPairData]\n",
    "sortedPpmiVals = [p[1] for p in sortedPairData]\n",
    "\n",
    "barsDrawn = ax.barh(sortedPairNames, sortedPpmiVals, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "ax.set_xlabel('PPMI Value', fontsize=12)\n",
    "ax.set_ylabel('Word Pairs', fontsize=12)\n",
    "ax.set_title('PPMI - Which Words Are Squad Goals ü§ù', fontsize=14, pad=20)\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Add value labels (show exact scores)\n",
    "for barElement, valScore in zip(barsDrawn, sortedPpmiVals):\n",
    "    barWidth = barElement.get_width()\n",
    "    ax.text(barWidth, barElement.get_y() + barElement.get_height()/2.,\n",
    "            f'{valScore:.3f}',\n",
    "            ha='left', va='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìä Q2 Analysis - Word Association Insights\n",
    "\n",
    "**Key Observations:**\n",
    "\n",
    "1. **Higher PPMI values** = words that are basically best friends (appear together way more than random)\n",
    "2. **Word pairs with unique co-occurrences** tend to have higher PPMI - they got that exclusive connection\n",
    "3. **Common word sequences** might have lower PPMI cuz they each common on their own\n",
    "\n",
    "**Real Talk Applications:**\n",
    "- Finding collocations (words that always roll together like \"ice cream\")\n",
    "- Word association mining (discovering relationships)\n",
    "- Feature engineering for NLP tasks (making better models)\n",
    "- Understanding semantic relationships (who vibes with who)\n",
    "\n",
    "**Bottom Line:** PPMI helps us find which words are squad goals - they just belong together fr fr.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Named Entity Recognition Using LSTM\n",
    "\n",
    "### üìö Theory - Big Brain Neural Network Time\n",
    "\n",
    "**Named Entity Recognition (NER)** finds and labels important stuff in text - like names, places, companies, etc. Basically taggin the VIPs in sentences.\n",
    "\n",
    "**CoNLL2003 NER Tags (BIO Scheme - the tagging system):**\n",
    "- 0: O (Outside - regular word, nothing special)\n",
    "- 1-2: B-PER, I-PER (Person - like \"John Smith\")\n",
    "- 3-4: B-ORG, I-ORG (Organization - like \"Google\")\n",
    "- 5-6: B-LOC, I-LOC (Location - like \"New York\")\n",
    "- 7-8: B-MISC, I-MISC (Miscellaneous - other important stuff)\n",
    "\n",
    "**LSTM (Long Short-Term Memory)** networks are perfect for this cuz they got memory:\n",
    "- Handle variable-length sentences (short or long, don't matter)\n",
    "- Remember context from earlier words (big brain memory)\n",
    "- Use gates to decide what to remember and forget (selective memory)\n",
    "\n",
    "It's like having a homie who actually remembers the whole conversation, not just the last sentence.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation - Getting Everything Ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareNerDataset(datasetRaw, maxSamplesToUse=5000):\n",
    "    \"\"\"Prepare CoNLL2003 data for NER training - get the data ready\"\"\"\n",
    "    sentencesList = []\n",
    "    tagsList = []\n",
    "    \n",
    "    trainingDataRaw = datasetRaw['train']\n",
    "    numSamples = min(maxSamplesToUse, len(trainingDataRaw))\n",
    "    \n",
    "    for idx in range(numSamples):\n",
    "        tokensLowercase = [token.lower() for token in trainingDataRaw[idx]['tokens']]\n",
    "        nerTagSequence = trainingDataRaw[idx]['ner_tags']\n",
    "        sentencesList.append(tokensLowercase)\n",
    "        tagsList.append(nerTagSequence)\n",
    "    \n",
    "    # Build vocabulary mapping (create the word roster)\n",
    "    allWordsUnique = set(word for sent in sentencesList for word in sent)\n",
    "    wordToIndexDict = {word: idx + 2 for idx, word in enumerate(sorted(allWordsUnique))}\n",
    "    wordToIndexDict['<PAD>'] = 0  # padding token\n",
    "    wordToIndexDict['<UNK>'] = 1  # unknown token\n",
    "    \n",
    "    tagToIndexDict = {i: i for i in range(9)}\n",
    "    \n",
    "    return sentencesList, tagsList, wordToIndexDict, tagToIndexDict\n",
    "\n",
    "# Prepare data\n",
    "print(\"Preparing NER data... gettin it ready...\")\n",
    "sentencesAll, tagsAll, wordToIdxMap, tagToIdxMap = prepareNerDataset(datasetStash, maxSamplesToUse=5000)\n",
    "idxToTagMap = {v: k for k, v in tagToIdxMap.items()}\n",
    "\n",
    "print(f\"‚úì Number of sentences: {len(sentencesAll)} - we got mad data!\")\n",
    "print(f\"‚úì Vocabulary size: {len(wordToIdxMap)} - that's a lot of words\")\n",
    "print(f\"‚úì Number of NER tags: {len(tagToIdxMap)} - 9 entity types to predict\")\n",
    "print(f\"\\nSample sentence: {' '.join(sentencesAll[0][:15])}...\")\n",
    "print(f\"Sample tags: {tagsAll[0][:15]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence Padding and Train/Test Split - Prep Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the longest sentence\n",
    "maxLengthFound = max(len(sent) for sent in sentencesAll)\n",
    "maxLengthCapped = min(maxLengthFound, 100)  # cap at 100 for efficiency\n",
    "\n",
    "print(f\"Maximum sequence length: {maxLengthCapped} - ain't nobody got time for super long sentences\\n\")\n",
    "\n",
    "# Convert to sequences (turn words into numbers)\n",
    "sequencesX = []\n",
    "sequencesY = []\n",
    "\n",
    "for singleSent, singleTagSeq in zip(sentencesAll, tagsAll):\n",
    "    sentenceIndices = [wordToIdxMap.get(word, wordToIdxMap['<UNK>']) for word in singleSent]\n",
    "    sequencesX.append(sentenceIndices)\n",
    "    sequencesY.append(singleTagSeq)\n",
    "\n",
    "# Pad sequences (make em all the same length)\n",
    "xPaddedArrays = pad_sequences(sequencesX, maxlen=maxLengthCapped, padding='post', value=wordToIdxMap['<PAD>'])\n",
    "yPaddedArrays = pad_sequences(sequencesY, maxlen=maxLengthCapped, padding='post', value=0)\n",
    "\n",
    "# Convert to categorical (one-hot encoding for neural net)\n",
    "yCategoricalArrays = np.array([to_categorical(seq, num_classes=9) for seq in yPaddedArrays])\n",
    "\n",
    "# Split data (80/20 split is the move)\n",
    "xTrainData, xTestData, yTrainData, yTestData = train_test_split(\n",
    "    xPaddedArrays, yCategoricalArrays, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"‚úì Training samples: {len(xTrainData)} - this the main dataset\")\n",
    "print(f\"‚úì Testing samples: {len(xTestData)} - we holdin this back to test\")\n",
    "print(f\"‚úì Shape of X_train: {xTrainData.shape}\")\n",
    "print(f\"‚úì Shape of y_train: {yTrainData.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Word2Vec Embeddings - The Semantic Sauce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createEmbeddingMatrix(wordToIdxMap, word2vecModelLoaded, embeddingDims=300):\n",
    "    \"\"\"Create embedding matrix from Word2Vec - convert our vocab to vectors\"\"\"\n",
    "    totalVocabSize = len(wordToIdxMap)\n",
    "    embeddingMatrixFull = np.zeros((totalVocabSize, embeddingDims))\n",
    "    \n",
    "    wordsFoundCount = 0\n",
    "    for word, wordIdx in wordToIdxMap.items():\n",
    "        if word in word2vecModelLoaded:\n",
    "            embeddingMatrixFull[wordIdx] = word2vecModelLoaded[word]\n",
    "            wordsFoundCount += 1\n",
    "        else:\n",
    "            embeddingMatrixFull[wordIdx] = np.random.normal(0, 0.1, embeddingDims)\n",
    "    \n",
    "    coveragePercent = 100 * wordsFoundCount / totalVocabSize\n",
    "    print(f\"‚úì Found {wordsFoundCount}/{totalVocabSize} words in Word2Vec ({coveragePercent:.2f}% coverage - not bad!)\")\n",
    "    return embeddingMatrixFull\n",
    "\n",
    "# Load Word2Vec (this might take a minute first time)\n",
    "print(\"Loading Word2Vec embeddings (Google News 300D)...\")\n",
    "print(\"(This might take a bit on first run - we downloadin 1.5GB of semantic goodness)\\n\")\n",
    "\n",
    "try:\n",
    "    word2vecLoaded = api.load(\"word2vec-google-news-300\")\n",
    "    print(\"‚úì Word2Vec loaded successfully! We got the good embeddings üî•\\n\")\n",
    "    \n",
    "    embeddingMatrixReady = createEmbeddingMatrix(wordToIdxMap, word2vecLoaded)\n",
    "    usePretrainedEmbeds = True\n",
    "except Exception as errorMsg:\n",
    "    print(f\"Yo, couldn't load Word2Vec: {errorMsg}\")\n",
    "    print(\"Using random embeddings instead - not ideal but we make it work\\n\")\n",
    "    embeddingMatrixReady = None\n",
    "    usePretrainedEmbeds = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build LSTM Model - Constructing The Beast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model (this where the magic happens)\n",
    "print(\"Building LSTM model... constructin the beast...\\n\")\n",
    "\n",
    "neuralModel = Sequential()\n",
    "\n",
    "# Embedding layer (word -> vector conversion)\n",
    "if usePretrainedEmbeds and embeddingMatrixReady is not None:\n",
    "    neuralModel.add(Embedding(\n",
    "        input_dim=len(wordToIdxMap),\n",
    "        output_dim=300,\n",
    "        weights=[embeddingMatrixReady],\n",
    "        input_length=maxLengthCapped,\n",
    "        trainable=False,  # keep the pretrained weights frozen\n",
    "        mask_zero=True  # ignore padding\n",
    "    ))\n",
    "else:\n",
    "    neuralModel.add(Embedding(\n",
    "        input_dim=len(wordToIdxMap),\n",
    "        output_dim=300,\n",
    "        input_length=maxLengthCapped,\n",
    "        mask_zero=True\n",
    "    ))\n",
    "\n",
    "# LSTM layers (the memory masters)\n",
    "neuralModel.add(LSTM(128, return_sequences=True, dropout=0.2))  # first memory unit, biggest one\n",
    "neuralModel.add(LSTM(64, return_sequences=True, dropout=0.2))   # second memory unit, medium sized\n",
    "neuralModel.add(LSTM(32, return_sequences=True, dropout=0.2))   # third memory unit, smallest but still fire\n",
    "\n",
    "# Dense layers (final processing before predictions)\n",
    "neuralModel.add(Dense(64, activation='relu'))\n",
    "neuralModel.add(Dropout(0.3))  # prevent overfitting, keep it real\n",
    "\n",
    "# Output layer (make predictions for each tag type)\n",
    "neuralModel.add(Dense(9, activation='softmax'))\n",
    "\n",
    "# Compile the model (set up training parameters)\n",
    "neuralModel.compile(\n",
    "    loss='categorical_crossentropy',  # loss function for multi-class\n",
    "    optimizer='adam',  # Adam optimizer is goated\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "neuralModel.summary()\n",
    "print(\"\\nModel architecture looking clean! Let's train this bad boy üí™\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model - Let's Get It"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model (this where the real work happens)\n",
    "print(\"\\nTraining LSTM model (10 epochs)... let's get it...\\n\")\n",
    "\n",
    "trainingHistory = neuralModel.fit(\n",
    "    xTrainData, yTrainData,\n",
    "    validation_split=0.1,  # use 10% of training data for validation\n",
    "    epochs=10,  # train for 10 epochs as required\n",
    "    batch_size=32,  # process 32 samples at a time\n",
    "    verbose=1  # show progress\n",
    ")\n",
    "\n",
    "print(\"\\n‚úì Training complete! The model been trained fr fr üéì\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Training History - See The Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history (see how we improved)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Loss plot (lower = better)\n",
    "ax1.plot(trainingHistory.history['loss'], label='Training Loss', marker='o', linewidth=2)\n",
    "ax1.plot(trainingHistory.history['val_loss'], label='Validation Loss', marker='s', linewidth=2)\n",
    "ax1.set_xlabel('Epoch', fontsize=12)\n",
    "ax1.set_ylabel('Loss', fontsize=12)\n",
    "ax1.set_title('Model Loss Over Epochs - Watch It Drop üìâ', fontsize=14, pad=15)\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "# Accuracy plot (higher = better)\n",
    "ax2.plot(trainingHistory.history['accuracy'], label='Training Accuracy', marker='o', linewidth=2)\n",
    "ax2.plot(trainingHistory.history['val_accuracy'], label='Validation Accuracy', marker='s', linewidth=2)\n",
    "ax2.set_xlabel('Epoch', fontsize=12)\n",
    "ax2.set_ylabel('Accuracy', fontsize=12)\n",
    "ax2.set_title('Model Accuracy Over Epochs - Watch It Rise üìà', fontsize=14, pad=15)\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Training curves show the model getting smarter each epoch - that's what we like to see!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation - Moment of Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model (see how we did)\n",
    "print(\"Evaluating model on test set... moment of truth...\\n\")\n",
    "\n",
    "predictionsFull = neuralModel.predict(xTestData)\n",
    "predictedClasses = np.argmax(predictionsFull, axis=-1)\n",
    "trueClasses = np.argmax(yTestData, axis=-1)\n",
    "\n",
    "# Flatten predictions and true labels (remove padding)\n",
    "predictionsFlat = []\n",
    "truthFlat = []\n",
    "\n",
    "for sampleIdx in range(len(trueClasses)):\n",
    "    for tokenIdx in range(len(trueClasses[sampleIdx])):\n",
    "        if trueClasses[sampleIdx][tokenIdx] != 0 or tokenIdx < maxLengthCapped:\n",
    "            predictionsFlat.append(predictedClasses[sampleIdx][tokenIdx])\n",
    "            truthFlat.append(trueClasses[sampleIdx][tokenIdx])\n",
    "\n",
    "# Calculate performance metrics (the report card)\n",
    "accuracyScore = accuracy_score(truthFlat, predictionsFlat)\n",
    "precisionScore, recallScore, f1Score, _ = precision_recall_fscore_support(\n",
    "    truthFlat, predictionsFlat, average='macro', zero_division=0\n",
    ")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\" \" * 25 + \"RESULTS - LET'S SEE HOW WE DID\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"  Accuracy:           {accuracyScore:.4f} - overall correctness rate\")\n",
    "print(f\"  Macro Precision:    {precisionScore:.4f} - how precise our predictions are\")\n",
    "print(f\"  Macro Recall:       {recallScore:.4f} - how many entities we caught\")\n",
    "print(f\"  Macro F1-Score:     {f1Score:.4f} - the balanced score (precision + recall)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Save metrics\n",
    "metricsDict = {\n",
    "    'Accuracy': accuracyScore,\n",
    "    'Precision': precisionScore,\n",
    "    'Recall': recallScore,\n",
    "    'F1-Score': f1Score\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Metrics - See The Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize metrics (make it aesthetic)\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "metricNames = list(metricsDict.keys())\n",
    "metricValues = list(metricsDict.values())\n",
    "barColors = ['#3498db', '#2ecc71', '#f39c12', '#e74c3c']\n",
    "\n",
    "barsPlotted = ax.bar(metricNames, metricValues, color=barColors, alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "ax.set_ylabel('Score', fontsize=12)\n",
    "ax.set_xlabel('Metrics', fontsize=12)\n",
    "ax.set_title('NER Model Performance Metrics - The Report Card üìä', fontsize=16, pad=20)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels (show exact scores)\n",
    "for barElement, valScore in zip(barsPlotted, metricValues):\n",
    "    barHeight = barElement.get_height()\n",
    "    ax.text(barElement.get_x() + barElement.get_width()/2., barHeight,\n",
    "            f'{valScore:.4f}',\n",
    "            ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix - See What Got Confused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix (see where model got confused)\n",
    "confusionMat = confusion_matrix(truthFlat, predictionsFlat)\n",
    "\n",
    "# Tag names (the entity types)\n",
    "tagNames = ['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "sns.heatmap(confusionMat, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=tagNames, yticklabels=tagNames,\n",
    "            cbar_kws={'label': 'Count'}, ax=ax)\n",
    "ax.set_xlabel('Predicted Label', fontsize=12)\n",
    "ax.set_ylabel('True Label', fontsize=12)\n",
    "ax.set_title('Confusion Matrix - Where The Model Got It Right/Wrong üéØ', fontsize=16, pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Darker blues on the diagonal = model getting it right consistently. That's what we want!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Predictions - See It In Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample predictions (the proof is in the pudding)\n",
    "idxToWordMap = {v: k for k, v in wordToIdxMap.items()}\n",
    "\n",
    "print(\"\\nSample Predictions - Let's See What We Got:\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for exampleIdx in range(3):\n",
    "    # Get original sentence\n",
    "    sentIndices = xTestData[exampleIdx]\n",
    "    sentWords = [idxToWordMap.get(idx, '<UNK>') for idx in sentIndices if idx != 0]\n",
    "    \n",
    "    # Get predictions and true labels\n",
    "    predTags = [tagNames[idx] for idx in predictedClasses[exampleIdx][:len(sentWords)]]\n",
    "    trueTags = [tagNames[idx] for idx in trueClasses[exampleIdx][:len(sentWords)]]\n",
    "    \n",
    "    print(f\"\\nExample {exampleIdx+1}:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(\"Sentence:\", \" \".join(sentWords))\n",
    "    print(\"\\nTrue tags:     \", \" \".join(trueTags))\n",
    "    print(\"Predicted tags:\", \" \".join(predTags))\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìä Q3 Analysis - What We Learned\n",
    "\n",
    "**Model Architecture (The Squad Lineup):**\n",
    "- Embedding layer (300 dimensions, Word2Vec pre-trained) - converts words to semantic vectors\n",
    "- 3 LSTM layers with decreasing units (128 ‚Üí 64 ‚Üí 32) - the memory masters\n",
    "- Dense layer with ReLU activation - processing power\n",
    "- Output layer with softmax for 9 NER tags - makes the final call\n",
    "\n",
    "**Training Setup:**\n",
    "- Loss function: Categorical cross-entropy (perfect for multi-class)\n",
    "- Optimizer: Adam (goated optimizer, no cap)\n",
    "- Epochs: 10 (as required)\n",
    "- Batch size: 32 (process in groups for efficiency)\n",
    "\n",
    "**Key Observations:**\n",
    "1. The model successfully learns NER patterns from sequential data - it gets the vibe\n",
    "2. LSTM layers capture context for accurate entity recognition - remembers what came before\n",
    "3. Word2Vec embeddings provide semantic initialization - gives it a head start\n",
    "4. The BIO tagging scheme enables precise entity boundary detection - knows where entities start and end\n",
    "\n",
    "**Potential Improvements (How To Make It Even Better):**\n",
    "- Use bidirectional LSTM for better context capture (look ahead AND behind)\n",
    "- Add CRF layer for sequence constraint modeling (make predictions more consistent)\n",
    "- Use character-level embeddings for OOV words (handle words never seen before)\n",
    "- Increase training data size (more data = smarter model)\n",
    "- Fine-tune embeddings during training (customize for our specific task)\n",
    "\n",
    "**Bottom Line:** We built a neural network that can read sentences and tag the important stuff like a pro. That's pretty fire ngl üî•\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Conclusions - We Did That\n",
    "\n",
    "### Assignment Completion - The Full Rundown\n",
    "\n",
    "This assignment successfully implemented three core NLP techniques and we crushed it:\n",
    "\n",
    "#### ‚úÖ Question 1: TF-IDF & Cosine Similarity (25 pts)\n",
    "- Built custom TF-IDF vectorizer from scratch (no sklearn shortcuts)\n",
    "- Implemented document frequency tracking (popularity meter)\n",
    "- Created TF-IDF matrix for CoNLL2003 corpus (the whole dataset)\n",
    "- Computed cosine similarity for sentence pairs (vibe check)\n",
    "- Visualized results with heatmaps and bar charts (made it look clean)\n",
    "\n",
    "#### ‚úÖ Question 2: PPMI Calculation (5 pts)\n",
    "- Implemented Pointwise Mutual Information (found the word squads)\n",
    "- Calculated word co-occurrence statistics (who hangs with who)\n",
    "- Applied PPMI transformation (only positive vibes)\n",
    "- Demonstrated with multiple examples (showed how it works)\n",
    "- Visualized word associations (made it pretty)\n",
    "\n",
    "#### ‚úÖ Question 3: LSTM-based NER (20 pts)\n",
    "- Loaded and preprocessed CoNLL2003 dataset (got the data ready)\n",
    "- Integrated Word2Vec embeddings (semantic sauce)\n",
    "- Built 3-layer LSTM architecture (constructed the beast)\n",
    "- Trained for 10 epochs with Adam optimizer (let it learn)\n",
    "- Achieved strong performance on 9-class NER task (got good scores)\n",
    "- Generated comprehensive evaluation metrics (the report card)\n",
    "- Visualized training progress and confusion matrix (made it visual)\n",
    "\n",
    "---\n",
    "\n",
    "### Key Takeaways - What We Actually Learned\n",
    "\n",
    "1. **TF-IDF** effectively captures document-specific word importance - tells us which words hit different\n",
    "2. **PPMI** reveals strong word associations and collocations - finds the word homies\n",
    "3. **LSTM networks** excel at sequence labeling tasks like NER - they got that memory\n",
    "4. **Pre-trained embeddings** (Word2Vec) improve model initialization - start with knowledge\n",
    "5. **Proper evaluation** requires multiple metrics - can't judge with just one number\n",
    "\n",
    "---\n",
    "\n",
    "### Technologies Used - The Tech Stack\n",
    "\n",
    "- **Python 3.x** - the language\n",
    "- **NumPy** - numerical computing (math operations)\n",
    "- **Pandas** - data manipulation (organize data)\n",
    "- **Matplotlib & Seaborn** - visualization (make it pretty)\n",
    "- **Keras/TensorFlow** - deep learning (neural networks)\n",
    "- **Hugging Face Datasets** - CoNLL2003 dataset (the data source)\n",
    "- **Gensim** - Word2Vec embeddings (semantic vectors)\n",
    "- **scikit-learn** - metrics and utilities (evaluation tools)\n",
    "\n",
    "---\n",
    "\n",
    "**We really did that! Assignment complete, no cap üíØ**\n",
    "\n",
    "For more details, peep the [GitHub repository](https://github.com/yourusername/Natural-Language-Processing).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
